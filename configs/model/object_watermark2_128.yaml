_target_: src.models.object_watermark2.ObjectWatermark2

model_cfg:
  image_shape: ${datamodule.dataset_cfg.image_shape}
  msg_len: ${datamodule.dataset_cfg.msg_len}
  adopt_seg_delay_step: 10000
  preprocess_bbox_crop_out: False
  # Please use `datamodule.dataset_cfg.random_translate`
  # preprocess_random_translate: ???
  preprocess_random_scale: False
  preprocess_random_rotate: False
  mask_object_on_train: True
  iou_thresh_for_segment_pred: 0.97
  iou_thresh_for_correct_ratio: 0.97
  adopt_all_seg_mask: False
  adopt_all_gt_mask: False
  lr: 0.0005

encoder:
  # _target_: src.models.encoder.DualAttentionEncoder
  # image_shape: ${model.model_cfg.image_shape}
  # secret_len: ${model.model_cfg.msg_len}
  # conv_type: conv
  # multi_level_embed: [True, False, False, False, False]
  # embed_factor: 1.  # Set to None for auto regression
  # pixel_shuffle_sample: False
  # embed_mode: space
  # self_attention: False

  _target_: src.models.encoder.StegaStampEncoder
  image_shape: ${model.model_cfg.image_shape}
  secret_len: ${model.model_cfg.msg_len}
  out_channels: 3
  conv_type: conv
  multi_level_embed: [True, False, False, False, False]
  embed_factor: 1.0  # Set to 0 for auto regression
  # embed_mode: Union[space_resize, space_repeat, channel, bbox]
  embed_mode: space_resize
  # mask_mode: Union[null, mask, forward_mask, concat]
  # Set `null` to do nothing
  # Set `mask` to mask the image
  # Set `forward_mask` to avoid mask gradient in the backward pass
  # Set `concat` to concatenate mask and image, please use once
  mask_object: mask
  mask_msg: null
  mask_residual: False    # Attention! it binds with `lpips_mask` in `loss_cfg`
  begin_ca: True
  mid_sa: True

  # _target_: src.models.encoder.UNetArch
  # msg_len: ${model.model_cfg.msg_len}
  # reduction: 16
  # deformable: False

  # _target_: src.models.encoder.ARWGANEncoder
  # image_shape: ${model.model_cfg.image_shape}
  # message_len: ${model.model_cfg.msg_len}
  # embed_factor: 1.

  # _target_: src.models.encoder.AttentionStegaStampEncoder
  # image_shape: ${model.model_cfg.image_shape}
  # secret_len: ${model.model_cfg.msg_len}
  # deformable_conv: False
  # multi_level_embed: [True, False, False, False, False]
  # attention_layer: [True, True, True, True, True, False, False, False, False, False]
  # mask_residual: True
  # embed_factor: 1.  # Set to None for auto regression
  # pixel_shuffle_sample: False

  # _target_: src.models.encoder.LXJEncoder
  # opt:
  #   network:
  #     in_channels: 3
  #     message_length: 64
  #     encoder:
  #       channels: 64
  #       growth_rate: 64

  # _target_: src.models.encoder.PIMoGEncoder
  # in_channels: 3
  # out_channels: 3
  # msg_len: ${model.model_cfg.msg_len}

  # _target_: src.models.encoder.PretrainedUNetEncoder
  # ni: 6
  # nf: 3
  # msg_len: ${model.model_cfg.msg_len}

decoder:
  # _target_: src.models.decoder.DualAttentionDecoder
  # image_shape: ${model.model_cfg.image_shape}
  # secret_len: ${model.model_cfg.msg_len}
  # conv_type: ${model.encoder.conv_type}
  # self_attention: ${model.encoder.self_attention}

  _target_: src.models.decoder.StegaStampWoSTNDecoder
  image_shape: ${model.model_cfg.image_shape}
  secret_len: ${model.model_cfg.msg_len}
  conv_type: ${model.encoder.conv_type}
  # mask_object: Union[null, mask, concat, batch_norm_mask]
  mask_object: mask
  arch_version: v0

  # _target_: src.models.decoder.HiDDeNDecoder
  # msg_len: ${model.model_cfg.msg_len}

  # _target_: src.models.decoder.ARWGANDecoder
  # image_shape: ${model.model_cfg.image_shape}
  # message_len: ${model.model_cfg.msg_len}

  # _target_: src.models.decoder.LXJDecoder
  # opt:
  #   network:
  #     in_channels: 3
  #     message_length: 64
  #     decoder:
  #       channels: 64
  #       growth_rate: 64

  # _target_: src.models.decoder.PIMoGExtractor
  # in_channels: 3
  # msg_len: ${model.model_cfg.msg_len}

augmenter:
  # _target_: src.models.augmenter.Augmenter
  # _target_: src.models.augmenter.GeometricCopypasteNoise
  _target_: src.models.augmenter.RandomSelectAugmenter
  device: cuda

  aug_dict:
    # No need identity, as low noise or blur is enough
    # Translate:
    #   # Have done in copy-paste process
    #   _target_: torch.nn.Identity
    Affine:
      _target_: kornia.augmentation.RandomAffine
      degrees: 45
      # translate: [0.2, 0.2]
      scale: [0.75, 1.5]
      # shear: 10.
      same_on_batch: False
      p: 1.

    # MotionBlur:
    #   _target_: kornia.augmentation.RandomMotionBlur
    #   _partial_: True
    #   # kernel_size: [3, 7] # Randomly choose a kernel size from 3 to 7
    #   angle: 90.
    #   direction: 0.5
    #   p: 0.9
    # ColorJitter:
    #   _target_: kornia.augmentation.ColorJitter
    #   brightness: 0.3
    #   contrast: 0.5
    #   saturation: 0.5
    #   hue: 0.1
    GaussianBlur:
      _target_: kornia.augmentation.RandomGaussianBlur
      kernel_size: [7, 7]
      sigma: [0.1, 2.0]  # Randomly choose sigma from 0.1 to 2.0
    Noise:
      _target_: kornia.augmentation.RandomGaussianNoise
      mean: 0.
      std: 0.05
    JPEG50:
      _target_: src.models.augmenter.DiffJPEG.DiffJPEG.DiffJPEG
      height: 256
      width: 256
      differentiable: True
      quality: 50
    JPEG75:
      _target_: src.models.augmenter.DiffJPEG.DiffJPEG.DiffJPEG
      height: 256
      width: 256
      differentiable: True
      quality: 75


segmenter:
  _target_: src.models.segmenter.SMPUNet

syncor:
  # _target_: src.models.syncor.SpatialTransNet
  # input_shape: [3, 256, 256]
  # _target_: src.models.syncor.PerspectiveTransformLayer
  # in_channels: 1
  # _target_: src.models.syncor.BBoxSTN
  # in_channels: 1
  # output_size: [256, 256]
  _target_: src.models.syncor.CentralMoment
  output_size: [128, 128]
  random_translate: False
  random_scale: False
  random_rotate: False
  bbox_crop_out: False
  # _target_: src.models.syncor.NoSync
  # _target_: src.models.syncor.CropOut
  # output_size: [256, 256]

loss_fn:
  pix_loss:
    # _target_: torch.nn.MSELoss
    _target_: src.models.loss_funcs.WeightedYUVLoss
    weights: [1, 100, 100]
    dist_type: l2

loss_cfg:
  vis_weight1: 1.5   # weight for pixel-level loss
  vis_weight2: 1.2  # weight for LPIPS loss
  lpips_mask: False
  vis_weight3: 0.   # weight for discriminator loss
  vis_weight: 1.
  vis_delay_step: 5000
  msg_weight: 2.
  seg_weight: 1.
  accu_mask_weight: False
